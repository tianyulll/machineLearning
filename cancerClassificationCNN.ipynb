{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bb52f34-a080-407f-b2d7-4bfe2ab9be00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import torchvision.transforms as T\n",
    "import torch.nn as nn\n",
    "from torchvision.utils import make_grid\n",
    "#from torchvision.utils import save_image\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8f70bb5-6f8c-462c-9c7c-b6ea3459d0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '2', '3', 'test']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\npituitary_brains = os.listdir(data_dir+\"/3\")\\nprint(\\'No. of training examples for pituitary tumor samples:\\', len(pituitary_brains))\\nprint(pituitary_brains[:5])\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proj_dir = 'd:/project'\n",
    "data_dir = 'd:/project/archive'\n",
    "classes = os.listdir(data_dir)\n",
    "print(classes)\n",
    "# meningioma(1), glioma(2), pituitary tumor(3) \n",
    "# separate trainign/test data\n",
    "'''\n",
    "pituitary_brains = os.listdir(data_dir+\"/3\")\n",
    "print('No. of training examples for pituitary tumor samples:', len(pituitary_brains))\n",
    "print(pituitary_brains[:5])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64e584bd-f6a7-4700-9e1d-5f0f365343b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "image_size = (512,512)\n",
    "transform = T.Compose([\n",
    "        T.Resize(image_size),\n",
    "        T.ToTensor()\n",
    "        ])\n",
    "'''\n",
    "from torchvision.transforms import ToTensor\n",
    "dataset = datasets.ImageFolder(data_dir, transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "620c479d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#some data is not in 512x512 size \n",
    "from PIL import Image\n",
    "path = data_dir+\"/3\"\n",
    "for images in os.listdir(path):\n",
    "    img = Image.open(path+\"/\"+images)\n",
    "    if img.width != 512:\n",
    "        print(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b1f97ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3050\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6359f87a-c799-4b78-97b5-9b49bb76da25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "matplotlib.rcParams['figure.facecolor'] = '#ffffff'\n",
    "\n",
    "def show_example(img, label):\n",
    "    print('Label: ', dataset.classes[label], \"(\"+str(label)+\")\")\n",
    "    plt.imshow(img.permute(1, 2, 0)) # matplotlib expects 0-dimension to be last. Permute function moves 0-dimention to last dimension for matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac884646-7748-4b17-a85a-52d5b440b847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x21f3ea24450>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_seed = 42\n",
    "torch.manual_seed(random_seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b37ce7f-50db-42af-8461-8ecd630ea54d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2550, 500)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split into training data, validating data. \n",
    "val_size = 500\n",
    "train_size = len(dataset) - val_size\n",
    "\n",
    "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
    "len(train_ds), len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f90407c-b14e-47cf-830d-0d0e2ddac876",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataloader\n",
    "train_dl = DataLoader(train_ds, batch_size=8, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_dl = DataLoader(val_ds, 16, num_workers= 4, pin_memory=True) # can double batch size in validation set b/c we aren't doing gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b749548",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convolutional neural network\n",
    "\n",
    "def apply_kernel(image, kernel):\n",
    "    ri, ci = image.shape\n",
    "    rk, ck = kernel.shape\n",
    "    ro, co = ri-rk+1, ci-ck+1\n",
    "    output = torch.zeros([ro, co])\n",
    "    for i in range (ro):\n",
    "        for j in range(co):\n",
    "            output[i,j] = torch.sum(image[i:i+rk,k:j+ck]*kernel)\n",
    "    return output\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "654799d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "144bfc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassificationBase(nn.Module):\n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch\n",
    "        out = self(images)\n",
    "        loss = F.cross_entropy(out, labels)\n",
    "        return loss\n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch\n",
    "        out = self(images)\n",
    "        loss = F.cross_entropy(out, labels)\n",
    "        acc = accuracy(out, labels)\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))\n",
    "        \n",
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d6fc6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cifar10CnnModel(ImageClassificationBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            \n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), \n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(16, 16),\n",
    "            \n",
    "            nn.Flatten(), \n",
    "            nn.Linear(512*4*4, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 10))\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5819dd0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cifar10CnnModel(\n",
       "  (network): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU()\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU()\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU()\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU()\n",
       "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (16): ReLU()\n",
       "    (17): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU()\n",
       "    (19): MaxPool2d(kernel_size=16, stride=16, padding=0, dilation=1, ceil_mode=False)\n",
       "    (20): Flatten(start_dim=1, end_dim=-1)\n",
       "    (21): Linear(in_features=8192, out_features=512, bias=True)\n",
       "    (22): ReLU()\n",
       "    (23): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (24): ReLU()\n",
       "    (25): Linear(in_features=256, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Cifar10CnnModel()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "327f4f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8994762"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([p.numel() for p in model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49ae107a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#allow GPU \\ndef get_default_device():\\n    if torch.cuda.is_available():\\n        return torch.device(\\'cuda\\')\\n    else:\\n        return torch.device(\\'cpu\\')\\n    \\ndef to_device(data, device):\\n    \"\"\"Move tensor(s) to chosen device\"\"\"\\n    if isinstance(data, (list,tuple)):\\n        return [to_device(x, device) for x in data]\\n    return data.to(device, non_blocking=True)\\n\\nclass DeviceDataLoader():\\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\\n    def __init__(self, dl, device):\\n        self.dl = dl\\n        self.device = device\\n        \\n    def __iter__(self):\\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\\n        for b in self.dl: \\n            yield to_device(b, self.device)\\n\\n    def __len__(self):\\n        \"\"\"Number of batches\"\"\"\\n        return len(self.dl)\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#allow GPU \n",
    "def get_default_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1dcc5ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model training\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "    for epoch in range(epochs):\n",
    "        # Training Phase \n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            train_losses.append(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        # Validation phase\n",
    "        result = evaluate(model, val_loader)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "057364c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#update dataset for GPU accelerate\\ndevice = get_default_device()\\ntrain_dl = DeviceDataLoader(train_dl, device)\\nval_dl = DeviceDataLoader(val_dl, device)\\nto_device(model, device)\\n\\nmodel = to_device(Cifar10CnnModel(), device)\\nevaluate(model, val_dl)\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#update dataset for GPU accelerate\n",
    "device = get_default_device()\n",
    "train_dl = DeviceDataLoader(train_dl, device)\n",
    "val_dl = DeviceDataLoader(val_dl, device)\n",
    "to_device(model, device)\n",
    "\n",
    "model = to_device(Cifar10CnnModel(), device)\n",
    "evaluate(model, val_dl)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "268d3c8e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_28192/3817548366.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(epochs, lr, model, train_loader, val_loader, opt_func)\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mtrain_losses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    397\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 399\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    400\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[1;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[1;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "num_epochs = 3\n",
    "opt_func = torch.optim.Adam\n",
    "lr = 0.001\n",
    "\n",
    "history = fit(num_epochs, lr, model, train_dl, val_dl, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "522be6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracies(history):\n",
    "    accuracies = [x['val_acc'] for x in history]\n",
    "    plt.plot(accuracies, '-x')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.title('Accuracy vs. No. of epochs')\n",
    "    \n",
    "\n",
    "def plot_losses(history):\n",
    "    train_losses = [x.get('train_loss') for x in history]\n",
    "    val_losses = [x['val_loss'] for x in history]\n",
    "    plt.plot(train_losses, '-bx')\n",
    "    plt.plot(val_losses, '-rx')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(['Training', 'Validation'])\n",
    "    plt.title('Loss vs. No. of epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf9b7d3d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_28192/2884717789.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot_accuracies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "plot_accuracies(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bd1e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f621662",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply model to new data\n",
    "def predict_image(img, model):\n",
    "    # Convert to a batch of 1\n",
    "    xb = to_device(img.unsqueeze(0), device)\n",
    "    # Get predictions from model\n",
    "    yb = model(xb)\n",
    "    # Pick index with highest probability\n",
    "    _, preds  = torch.max(yb, dim=1)\n",
    "    # Retrieve the class label\n",
    "    return dataset.classes[preds[0].item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c65b355",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1, lb1 = dataset[555]\n",
    "predict_image(img1, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0d0633",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model\n",
    "torch.save(model.state_dict(), '10cnn.pth')\n",
    "model2 = to_device(Cifar10CnnModel(), device)\n",
    "model2.load_state_dict(torch.load('10cnn.pth'))\n",
    "predict_image(img1, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e2164c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
